# Configure preferences for Ollama
PREFERRED_PROVIDER="ollama"
OLLAMA_API_BASE="http://localhost:11434"
BIG_MODEL="codellama:34b-instruct"
SMALL_MODEL="codellama:34b-instruct"

# Fallback API keys (not needed for Ollama but good for fallback)
ANTHROPIC_API_KEY=""
OPENAI_API_KEY=""
GEMINI_API_KEY="" 
